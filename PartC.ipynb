{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Project2-PartC.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [
    "CjV8FVDP5nAS",
    "ufwbjh1x58Pr"
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RgKlxpR-BeDx",
    "pycharm": {}
   },
   "source": [
    "#### Adamantios Zaras AM: 06\n",
    "#### Panagiotis Souranis AM: 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvMOu3Fd4z9P",
    "pycharm": {}
   },
   "source": [
    "# Description\n",
    "\n",
    "In this part of the project, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJmPyewf44XC",
    "pycharm": {}
   },
   "source": [
    "# Global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjV8FVDP5nAS",
    "pycharm": {}
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bu-On9DmdNy0",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "outputId": "63b96977-a90a-4f34-d9b4-52224fe3059f"
   },
   "source": [
    "!pip install scikit-multilearn && \\\n",
    "git clone https://github.com/hsoleimani/MLTM.git"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Collecting scikit-multilearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/1f/e6ff649c72a1cdf2c7a1d31eb21705110ce1c5d3e7e26b2cc300e1637272/scikit_multilearn-0.2.0-py3-none-any.whl (89kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 5.8MB/s \n",
      "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
      "Successfully installed scikit-multilearn-0.2.0\n",
      "Cloning into 'MLTM'...\n",
      "remote: Enumerating objects: 3597, done.\u001b[K\n",
      "remote: Total 3597 (delta 0), reused 0 (delta 0), pack-reused 3597\n",
      "Receiving objects: 100% (3597/3597), 26.76 MiB | 25.39 MiB/s, done.\n",
      "Resolving deltas: 100% (349/349), done.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "Ubj0XegWl_QS",
    "pycharm": {},
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "outputId": "a9787fed-e223-4bf1-e709-b7d1145212f7"
   },
   "source": [
    "import warnings\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats as sp\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from utils import load_dataset, hyperparameters_search\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufwbjh1x58Pr",
    "pycharm": {}
   },
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "ktwINyCB5_vQ",
    "pycharm": {},
    "outputId": "ec8116b3-0a66-45ec-ba0c-57f0dd8be35b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    }
   },
   "source": [
    "# Load dataset.\n",
    "X_train, y_train, X_test, y_test, word_index = load_dataset(ngram_range=1, path='MLTM/Data/Delicious', maxlen=200)\n",
    "labels = ['programming','style','reference','java','web','internet','culture',\n",
    "'design','education','language','books','writing','computer','english','politics','history','philosophy',\n",
    "'science','religion','grammar']\n",
    "\n",
    "# Get the most frequent class only.\n",
    "print('\\nGetting the most frequent class...')\n",
    "most_frequent_counts = np.sum(np.transpose(y_train),axis=1)\n",
    "most_frequent_index = most_frequent_counts.argmax()\n",
    "y_train = y_train[:, most_frequent_index]\n",
    "y_test = y_test[:, most_frequent_index]\n",
    "print('The most frequent class was the word \\'{}\\', with {} appearances.'\n",
    "      .format(labels[most_frequent_index], most_frequent_counts.max()))\n",
    "\n",
    "# Split test set to test and unlabeled.\n",
    "print('Splitting test data to test and unlabeled sets.')\n",
    "X_unlabeled, X_test, y_hidden, y_test = train_test_split(\n",
    "    X_test, y_test, test_size=.5, random_state=0)\n",
    "print('{} test sequences.'.format(X_test.shape[0]))\n",
    "print('{} unlabeled sequences.'.format(X_unlabeled.shape[0]))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "8251 train sequences\n",
      "3983 test sequences\n",
      "X_train shape: (8251, 200)\n",
      "X_test shape: (3983, 200)\n",
      "\n",
      "Getting the most frequent class...\n",
      "The most frequent class was the word 'reference', with 3181 appearences.\n",
      "Splitting test data to test and unlabeled sets.\n",
      "1992 test sequences.\n",
      "1991 unlabeled sequences.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhkyoXcHrwZ2",
    "colab_type": "text"
   },
   "source": [
    "# Hyperparameters search"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rtu6QTP0sfcM",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Define classifiers.\n",
    "classifiers = {\n",
    "        'SVM': LinearSVC(random_state=0),\n",
    "        'Tree': DecisionTreeClassifier(random_state=0),\n",
    "        'Bayes': MultinomialNB()\n",
    "}"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFt5qwY3sQb_",
    "colab_type": "text"
   },
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bHwGpq6Arz3c",
    "colab_type": "code",
    "outputId": "e4865c52-82e1-4e01-dcf8-db721718c90d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    }
   },
   "source": [
    "# Create param dists.\n",
    "svm_param_dist = {'C': 10 ** np.random.uniform(-3, 3, size=7000)}\n",
    "tree_param_dist = {'max_depth': scipy.stats.randint(1, 30),\n",
    "                   'max_features': scipy.stats.randint(1, X_train.shape[1]),\n",
    "                   'min_samples_split': scipy.stats.randint(2, X_train.shape[0] / 2),\n",
    "                   'criterion': ['gini', 'entropy']\n",
    "}\n",
    "# Add param dists to a list.\n",
    "params_list = [svm_param_dist, tree_param_dist]\n",
    "\n",
    "# Perform random search.\n",
    "for key, classifier ,params in zip(classifiers.keys(), classifiers.values(), params_list):\n",
    "    hyperparameters_search(classifier, params, X_train, y_train, 'Accuracy',\n",
    "                           {'Accuracy': make_scorer(accuracy_score)}, key, \n",
    "                           candidates=100, cv=5, random_search=True, verbose=5)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Εstimator : SVM\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  5.2min\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ld18AbB14bqy"
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "awxmc3yx4bq-",
    "outputId": "458d34ae-9d2d-4ab4-d1fe-1b0df919d3de",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1413
    }
   },
   "source": [
    "# Create parameter grids.\n",
    "svm_grid = {'C': np.arange(290, 310, .5)}\n",
    "tree_grid = {\n",
    "        'max_depth': range(1, 2),\n",
    "        'max_features': range(129, 131),\n",
    "        'min_samples_split': range(3868, 3872),\n",
    "        'criterion': ['gini']\n",
    "}\n",
    "bayes_grid = {'alpha': np.arange(0, 10, 0.2)}\n",
    "# Add param grids to a list.\n",
    "params_list = [svm_grid, tree_grid, bayes_grid]\n",
    "\n",
    "# Perform grid search.\n",
    "for key, classifier ,params in zip(classifiers.keys(), classifiers.values(), params_list):\n",
    "    hyperparameters_search(classifier, params, X_train, y_train, 'Accuracy',\n",
    "                           {'Accuracy': make_scorer(accuracy_score)}, key, \n",
    "                           cv=10, random_search=False, verbose=10)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "\n",
      "Εstimator : SVM\n",
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   50.4s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed: 14.9min\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed: 20.1min\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed: 26.0min\n",
      "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed: 33.6min finished\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Best parameters found for Estimator : SVM\n",
      "{'C': 290.0}\n",
      "\n",
      "Best score found for Accuracy Score metric : 0.505\n",
      "\n",
      "Εstimator : Tree\n",
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1517s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    5.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0933s.) Setting batch_size=4.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Best parameters found for Estimator : Tree\n",
      "{'criterion': 'gini', 'max_depth': 1, 'max_features': 129, 'min_samples_split': 3868}\n",
      "\n",
      "Best score found for Accuracy Score metric : 0.614\n",
      "\n",
      "Εstimator : Bayes\n",
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=-1)]: Done 172 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 260 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done 364 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=-1)]: Done 424 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 484 tasks      | elapsed:   15.7s\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Best parameters found for Estimator : Bayes\n",
      "{'alpha': 4.800000000000001}\n",
      "\n",
      "Best score found for Accuracy Score metric : 0.491\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   16.2s finished\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AToVtWTGtIlt",
    "colab_type": "text"
   },
   "source": [
    "## Final classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-RD8o9IjtOt-",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create the best classifier found from the search.\n",
    "clf = LinearSVC(C=10, random_state=0)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oOgguTVr0ys",
    "colab_type": "text"
   },
   "source": [
    "# Apply Method"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jd0tKq86cEea",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Initialize lists to hold the accuracy results of the two methods.\n",
    "uncertainty_accuracies, random_accuracies = [], []\n",
    "\n",
    "# Initialize uncertainty sampling data.\n",
    "X_train_us = X_train.copy()\n",
    "y_train_us = y_train.copy()\n",
    "X_unlabeled_us = X_unlabeled.copy()\n",
    "y_unlabeled_us = y_hidden.copy()\n",
    "\n",
    "# Initialize random sampling data.\n",
    "X_train_rs = X_train.copy()\n",
    "y_train_rs = y_train.copy()\n",
    "X_unlabeled_rs = X_unlabeled.copy()\n",
    "y_unlabeled_rs = y_hidden.copy()\n",
    "\n",
    "# Run uncertainty sampling and random sampling methods, for 10 iterations.\n",
    "n_iterations = 10\n",
    "for i in range(n_iterations):\n",
    "    print('Iteration {}/{}'.format(i + 1, n_iterations))\n",
    "\n",
    "    print('Fitting on uncertainty sampling training set...')\n",
    "    # Train classifier with uncertainty sampling training set.\n",
    "    clf.fit(X_train_us, y_train_us)\n",
    "    # Predict on test data.\n",
    "    y_pred_us = clf.predict(X_test)\n",
    "    # Get the most uncertain sample from the unlabeled pool, \n",
    "    # by choosing the sample which is closest to the hyperplane.\n",
    "    uncertain_sample = X_test[np.argmin(np.abs(clf.decision_function(X_unlabeled_us)))]\n",
    "    # Calculate accuracy.\n",
    "    acc_us = accuracy_score(y_pred_us, y_test)\n",
    "    # Append current accuracy to the uncertainty accuracies array.\n",
    "    uncertainty_accuracies.append(acc_us)\n",
    "    # Store accuracy in uncertainty sampling accuracies.\n",
    "    uncertainty_accuracies.append(acc_us)\n",
    "    # Update uncertainty sampling data.\n",
    "    X_train_us = np.vstack((X_train_us, X_unlabeled_us[uncertain_sample, :]))\n",
    "    y_train_us = np.hstack((y_train_us, y_unlabeled_us[uncertain_sample]))\n",
    "    X_unlabeled_us = np.delete(X_unlabeled_us, uncertain_sample, 0)\n",
    "    y_unlabeled_us = np.delete(y_unlabeled_us, uncertain_sample, 0)\n",
    "    print('Predicted accuracy was {}'.format(acc_us))\n",
    "\n",
    "    print('Fitting on random sampling training set...')\n",
    "    # Train classifier with random sampling training set.\n",
    "    clf.fit(X_train_rs, y_train_rs)\n",
    "    # Predict on test data. \n",
    "    y_pred_rs = clf.predict(X_test)\n",
    "    # Get a random unlabeled sample.\n",
    "    random_sample = randint(0, len(y_unlabeled_rs))\n",
    "    # Calculate accuracy.\n",
    "    acc_rs = accuracy_score(y_pred_rs, y_test)\n",
    "    # Append current accuracy to the random accuracies array.\n",
    "    random_accuracies.append(acc_rs)\n",
    "    # Store accuracy in random sampling accuracies.\n",
    "    random_accuracies.append(acc_rs)\n",
    "    # Update random sampling data.\n",
    "    X_train_rs = np.vstack((X_train_rs, X_unlabeled_rs[random_sample, :]))\n",
    "    y_train_rs = np.hstack((y_train_rs, y_unlabeled_rs[random_sample]))\n",
    "    X_unlabeled_rs = np.delete(X_unlabeled_rs, random_sample, 0)\n",
    "    y_unlabeled_rs = np.delete(y_unlabeled_rs, random_sample, 0)\n",
    "    print('Predicted accuracy was {}'.format(acc_rs))"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ziyppe0oFUT",
    "colab_type": "text"
   },
   "source": [
    "## Plot Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMZRnS2kqcFN",
    "colab_type": "text"
   },
   "source": [
    "Finally, we plot the learning curves of the two methods, in order to compare them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mz92hVF4oCC2",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Create a figure.\n",
    "plt.figure()\n",
    "# Set title and labels.\n",
    "plt.title('Uncertainty Sampling vs Random Sampling Learning Curves')\n",
    "plt.xlabel('Number Of Instance Queries')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Create a plot grid.\n",
    "plt.grid()\n",
    "# Plot uncertainty and random sampling learning curves.\n",
    "plt.plot(range(n_iterations), uncertainty_accuracies, 'o-', color=\"r\",\n",
    "         label=\"Uncertainty Sampling\")\n",
    "plt.plot(range(n_iterations), random_accuracies, 'o-', color=\"g\",\n",
    "         label=\"Random Sampling\")\n",
    "\n",
    "# Show legends, placed at the best possible location.\n",
    "plt.legend(loc=\"best\")"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxLTJtZGqqBf",
    "colab_type": "text"
   },
   "source": [
    "As we can see, "
   ]
  }
 ]
}